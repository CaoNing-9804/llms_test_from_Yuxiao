# llms_test
code_review



# Requirements

`pip install git+https://github.com/huggingface/transformers.git@main accelerate`

`pip install optimum`

`pip install auto-gptq`


## How To Use

Run codellama_test.py for the test of CodeLlama

Run starchat_test.py for the test of Starchat

Bothe files generate output results in "result" folder 

Run llms_test_matrix.py to generate Confusion Matrix and Accuracy

